/************************************************************************
Copyright (C) 2003-2014 STMicroelectronics. All Rights Reserved.

This file is part of the Streaming Engine.

Streaming Engine is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License version 2 as
published by the Free Software Foundation.

Streaming Engine is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along
with Streaming Engine; see the file COPYING.  If not, write to the Free
Software Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307,
USA.

The Streaming Engine Library may alternatively be licensed under a
proprietary license from ST.
************************************************************************/

#include "manifestor_base.h"
#include "metadata_helper.h"

#undef TRACE_TAG
#define TRACE_TAG   "BaseMetadataHelper_c"

//{{{  setVideoUncompressedMetadata
//{{{  doxynote
/// \brief                           set uncompressed video metadata
/// \param ManifestationComponent    Decode Buffer Component Type
/// \param DecodeBufferManager       Decode Buffer Manager
/// \param Buffer                    Buffer containing the Frame
/// \param Meta                      Pointer to uncompressed metadata structure
/// \param VideoParameters           Display positioning information generated by frame parser
/// \param UseWindowOfInterest       Indicate whether we should fill the window of interest field with parsed information (e.g. pan-scan)
///                                  or with the full picture rectangle
/// \return                          void
//}}}
void BaseMetadataHelper_c::setVideoUncompressedMetadata(
    DecodeBufferComponentType_t           ManifestationComponent,
    DecodeBufferManager_t                 DecodeBufferManager,
    class Buffer_c                       *Buffer,
    stm_se_uncompressed_frame_metadata_t *Meta,
    struct ParsedVideoParameters_s       *VideoParameters,
    bool                                  UseWindowOfInterest)
{
    Rational_t                          FrameRate;
    Rational_t                          PictureAspectRatio;
    unsigned int                        DecodedHeight;
    unsigned int                        Shift;
    unsigned int                        Offset;

    // Fill generic info
    Meta->user_data_size                     = 0;
    Meta->user_data_buffer_address           = NULL;
    Meta->media                              = STM_SE_ENCODE_STREAM_MEDIA_VIDEO;
    Meta->discontinuity                      = STM_SE_DISCONTINUITY_CONTINUOUS;
    FrameRate                                = VideoParameters->Content.FrameRate;
    FrameRate.Restrict();
    Meta->video.frame_rate.framerate_num     = (uint32_t)(FrameRate.GetNumerator());
    Meta->video.frame_rate.framerate_den     = (uint32_t)(FrameRate.GetDenominator());
    Meta->video.pitch                        = DecodeBufferManager->ComponentStride(Buffer, ManifestationComponent, 0, 0);
    Meta->video.video_parameters.width       = VideoParameters->Content.Width;
    Meta->video.video_parameters.height      = VideoParameters->Content.Height;
    Meta->video.video_parameters.scan_type   = (VideoParameters->Content.Progressive == true) ? STM_SE_SCAN_TYPE_PROGRESSIVE :
                                               STM_SE_SCAN_TYPE_INTERLACED;
    //
    // Calculate Vertical Alignment
    //
    // Get Y dimension
    DecodedHeight = DecodeBufferManager->ComponentDimension(Buffer, ManifestationComponent, 1);
    // Is Aligned Height > Video Height ?
    Offset = DecodedHeight > VideoParameters->Content.Height ? (DecodedHeight - VideoParameters->Content.Height) : 0;
    // Detect first non-zero bit
    Shift  = 0;

    // Condition (Offset > (1 << (Shift - 1)) || Shift == 0) is removed as Shift  = 0
    while (!(DecodedHeight & 0x1) && (DecodedHeight != 0) && (Offset > 0))
    {
        DecodedHeight >>= 1;
        Shift++;
    }
    Meta->video.vertical_alignment          = (1 << Shift);

    //
    // Calculate Picture Aspect Ratio
    //
    Meta->video.video_parameters.pixel_aspect_ratio_numerator   = VideoParameters->Content.PixelAspectRatio.GetNumerator();
    Meta->video.video_parameters.pixel_aspect_ratio_denominator = VideoParameters->Content.PixelAspectRatio.GetDenominator();

    if (VideoParameters->Content.Height)
    {
        PictureAspectRatio  = Rational_t(VideoParameters->Content.Width, VideoParameters->Content.Height) *
                              VideoParameters->Content.PixelAspectRatio;
    }
    else
    {
        SE_WARNING("VideoParameters->Content.Height 0; forcing 1:1\n");
        PictureAspectRatio = Rational_t(1, 1) * VideoParameters->Content.PixelAspectRatio;
    }

    if (PictureAspectRatio == Rational_t(221, 100))
    {
        Meta->video.video_parameters.aspect_ratio = STM_SE_ASPECT_RATIO_221_1;
    }
    else if (PictureAspectRatio == Rational_t(4, 3))
    {
        Meta->video.video_parameters.aspect_ratio = STM_SE_ASPECT_RATIO_4_BY_3;
    }
    else if (PictureAspectRatio == Rational_t(16, 9))
    {
        Meta->video.video_parameters.aspect_ratio = STM_SE_ASPECT_RATIO_16_BY_9;
    }
    else
    {
        Meta->video.video_parameters.aspect_ratio = STM_SE_ASPECT_RATIO_UNSPECIFIED;
    }

    // We do not support 3D encoding yet
    Meta->video.video_parameters.format_3d      = STM_SE_FORMAT_3D_NONE;
    Meta->video.video_parameters.left_right_format  = false;

    // Interpreting colorspace from matrix coefficients
    switch (VideoParameters->Content.ColourMatrixCoefficients)
    {
    case MatrixCoefficients_ITU_R_BT601:
        Meta->video.video_parameters.colorspace = STM_SE_COLORSPACE_SMPTE170M;
        break;

    case MatrixCoefficients_ITU_R_BT709:
        Meta->video.video_parameters.colorspace = STM_SE_COLORSPACE_BT709;
        break;

    case MatrixCoefficients_ITU_R_BT470_2_M:
        Meta->video.video_parameters.colorspace = STM_SE_COLORSPACE_BT470_SYSTEM_M;
        break;

    case MatrixCoefficients_ITU_R_BT470_2_BG:
        Meta->video.video_parameters.colorspace = STM_SE_COLORSPACE_BT470_SYSTEM_BG;
        break;

    case MatrixCoefficients_SMPTE_170M:
        Meta->video.video_parameters.colorspace = STM_SE_COLORSPACE_SMPTE170M;
        break;

    case MatrixCoefficients_SMPTE_240M:
        Meta->video.video_parameters.colorspace = STM_SE_COLORSPACE_SMPTE240M;
        break;

    default:
        Meta->video.video_parameters.colorspace = STM_SE_COLORSPACE_UNSPECIFIED;
        break;
    }

    //
    // Fill Window Of Interest
    //

    // Default case is to use the full picture rectangle
    Meta->video.window_of_interest.x      = 0;
    Meta->video.window_of_interest.y      = 0;
    Meta->video.window_of_interest.width  = VideoParameters->Content.Width;
    Meta->video.window_of_interest.height = VideoParameters->Content.Height;

    if (UseWindowOfInterest)
    {
        // By default, fill the window of interest with the DisplayX/DisplayY/DisplayWidth/DisplayHeight rectangle
        Meta->video.window_of_interest.x      = VideoParameters->Content.DisplayX;
        Meta->video.window_of_interest.y      = VideoParameters->Content.DisplayY;
        Meta->video.window_of_interest.width  = VideoParameters->Content.DisplayWidth;
        Meta->video.window_of_interest.height = VideoParameters->Content.DisplayHeight;

        // If reliable pan-scan data is available, overwrite it by the broadcasted pan-scan window
        if (VideoParameters->PanScanCount > 0)
        {
            // Always use the first entry only in the pan-scan info table
            int HorizontalOffset = VideoParameters->PanScan[0].HorizontalOffset / 16;
            int VerticalOffset   = VideoParameters->PanScan[0].VerticalOffset / 16;

            // Do not take into account a pan-scan rectangle which does not fit within the full frame rectangle
            if ((HorizontalOffset >= 0) &&
                ((HorizontalOffset + VideoParameters->PanScan[0].Width) <= VideoParameters->Content.Width) &&
                (VerticalOffset >= 0) &&
                ((VerticalOffset + VideoParameters->PanScan[0].Height) <= VideoParameters->Content.Height))
            {
                Meta->video.window_of_interest.x      = HorizontalOffset;
                Meta->video.window_of_interest.y      = VerticalOffset;
                Meta->video.window_of_interest.width  = VideoParameters->PanScan[0].Width;
                Meta->video.window_of_interest.height = VideoParameters->PanScan[0].Height;
            }
        }
    }

    // Fill Picture Type
    switch (VideoParameters->SliceType)
    {
    case SliceTypeI:
        Meta->video.picture_type = STM_SE_PICTURE_TYPE_I;
        break;

    case SliceTypeP:
        Meta->video.picture_type = STM_SE_PICTURE_TYPE_P;
        break;

    case SliceTypeB:
        Meta->video.picture_type = STM_SE_PICTURE_TYPE_B;
        break;

    default:
        Meta->video.picture_type = STM_SE_PICTURE_TYPE_UNKNOWN;
        break;
    }

    // Fill Surface Format
    switch (DecodeBufferManager->ComponentDataType(ManifestationComponent))
    {
    case FormatMarkerFrame:
        Meta->video.surface_format = SURFACE_FORMAT_MARKER_FRAME;
        break;

    case FormatAudio:
        Meta->video.surface_format = SURFACE_FORMAT_AUDIO;
        break;

    case FormatVideo420_MacroBlock:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_420_MACROBLOCK;
        break;

    case FormatVideo420_PairedMacroBlock:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_420_PAIRED_MACROBLOCK;
        break;

    case FormatVideo422_Raster:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_422_RASTER;
        break;

    case FormatVideo420_Planar:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_420_PLANAR;
        break;

    case FormatVideo420_PlanarAligned:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_420_PLANAR_ALIGNED;
        break;

    case FormatVideo422_Planar:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_422_PLANAR;
        break;

    case FormatVideo8888_ARGB:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_8888_ARGB;
        break;

    case FormatVideo888_RGB:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_888_RGB;
        break;

    case FormatVideo565_RGB:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_565_RGB;
        break;

    case FormatVideo422_YUYV:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_422_YUYV;
        break;

    case FormatVideo420_Raster2B:
        Meta->video.surface_format = SURFACE_FORMAT_VIDEO_420_RASTER2B;
        break;

    // Unsupported conversion types set as UNKNOWN
    default:
    case FormatLinear:
    case FormatPerMacroBlockLinear:

    //case FormatVideo420_Raster_Y_CbCr:
    //case FormatVideo420_Raster_Y_Cb_Cr:
    case FormatUnknown:
        Meta->video.surface_format = SURFACE_FORMAT_UNKNOWN;
        break;
    }

    // Specify top field first for interlace frames
    Meta->video.top_field_first = VideoParameters->TopFieldFirst;
}
